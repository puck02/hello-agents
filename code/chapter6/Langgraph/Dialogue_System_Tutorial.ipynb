{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091d3619",
   "metadata": {},
   "source": [
    "# 🎓 LangGraph 智能搜索助手教程\n",
    "\n",
    "欢迎来到 LangGraph 入门教程！本教程将带你从零开始，学习如何使用 LangGraph 框架构建一个智能搜索助手。\n",
    "\n",
    "## 📚 你将学到什么\n",
    "\n",
    "1. 什么是 LangGraph，它能做什么\n",
    "2. 如何定义工作流的\"状态\"\n",
    "3. 如何创建多个\"节点\"（处理步骤）\n",
    "4. 如何连接节点形成完整的工作流\n",
    "5. 如何集成真实的搜索 API（Tavily）\n",
    "\n",
    "## 🎯 项目功能\n",
    "\n",
    "我们将构建一个智能搜索助手，它能：\n",
    "- 理解用户的问题\n",
    "- 自动生成最佳搜索关键词\n",
    "- 调用 Tavily API 搜索真实信息\n",
    "- 基于搜索结果生成专业回答\n",
    "\n",
    "## ⚙️ 准备工作\n",
    "\n",
    "你需要准备：\n",
    "1. Python 3.8 及以上版本\n",
    "2. 安装必要的 Python 包\n",
    "3. Tavily API Key（用于搜索功能）\n",
    "4. OpenAI API Key（或其他兼容的 LLM）\n",
    "\n",
    "让我们开始吧！ 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabbed9",
   "metadata": {},
   "source": [
    "## 第 1 步：导入必要的库\n",
    "\n",
    "首先，我们需要导入项目用到的所有 Python 库。别担心，我会逐一解释它们的作用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee3fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有库导入成功！\n"
     ]
    }
   ],
   "source": [
    "# 异步编程支持 - 让程序可以同时做多件事\n",
    "import asyncio\n",
    "\n",
    "# Python 类型注解工具 - 让代码更规范、更容易理解\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "# LangChain 消息类型 - 用于表示对话中的不同角色\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# OpenAI 聊天模型 - 我们将使用的 AI 大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangGraph 核心组件 - 用于构建工作流\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 内存存储器 - 用于保存对话历史\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 系统工具\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Tavily 搜索客户端 - 用于真实的网络搜索\n",
    "from tavily import TavilyClient\n",
    "\n",
    "print(\"✅ 所有库导入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2359d4",
   "metadata": {},
   "source": [
    "### 📖 库的作用说明\n",
    "\n",
    "- **asyncio**: Python 的异步编程库，让程序可以\"同时\"处理多个任务\n",
    "- **TypedDict**: 定义字典的结构，告诉 Python 我们的字典里有哪些键和值\n",
    "- **LangChain**: AI 应用开发框架，提供了很多便利的工具\n",
    "- **LangGraph**: 用于构建多步骤 AI 工作流的框架（今天的主角！）\n",
    "- **Tavily**: 一个专为 AI 应用设计的搜索 API\n",
    "- **dotenv**: 从 .env 文件加载环境变量（保护你的 API Key）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeea03c",
   "metadata": {},
   "source": [
    "## 第 2 步：加载环境变量\n",
    "\n",
    "环境变量是用来存储敏感信息（如 API Key）的安全方式。我们不会把 API Key 直接写在代码里，而是从 `.env` 文件中读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a91a0084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 环境变量加载完成！\n",
      "💡 提示：请确保你的 .env 文件包含以下变量：\n",
      "   - LLM_API_KEY (你的 AI 模型 API Key)\n",
      "   - LLM_BASE_URL (API 地址，可选)\n",
      "   - LLM_MODEL (模型名称，如 gpt-4o-mini)\n",
      "   - TAVILY_API_KEY (Tavily 搜索 API Key)\n"
     ]
    }
   ],
   "source": [
    "# 从 .env 文件加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ 环境变量加载完成！\")\n",
    "print(\"💡 提示：请确保你的 .env 文件包含以下变量：\")\n",
    "print(\"   - LLM_API_KEY (你的 AI 模型 API Key)\")\n",
    "print(\"   - LLM_BASE_URL (API 地址，可选)\")\n",
    "print(\"   - LLM_MODEL (模型名称，如 gpt-4o-mini)\")\n",
    "print(\"   - TAVILY_API_KEY (Tavily 搜索 API Key)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d21509",
   "metadata": {},
   "source": [
    "### 📝 创建 .env 文件示例\n",
    "\n",
    "在项目根目录创建一个名为 `.env` 的文件，内容如下：\n",
    "\n",
    "```\n",
    "LLM_API_KEY=sk-your-openai-api-key\n",
    "LLM_BASE_URL=https://api.openai.com/v1\n",
    "LLM_MODEL=gpt-4o-mini\n",
    "TAVILY_API_KEY=tvly-your-tavily-api-key\n",
    "```\n",
    "\n",
    "注意：将上面的值替换为你自己的 API Key。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b44b17",
   "metadata": {},
   "source": [
    "## 第 3 步：定义工作流状态\n",
    "\n",
    "在 LangGraph 中，**状态（State）** 是在整个工作流中流转的数据。就像一个\"传递包裹\"的游戏，每个节点都会接收这个包裹，处理一下，然后传给下一个节点。\n",
    "\n",
    "我们需要明确定义这个\"包裹\"里有什么东西。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10a518e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 状态结构定义完成！\n",
      "📦 我们的状态包含 6 个字段：\n",
      "   1. messages - 对话历史\n",
      "   2. user_query - 用户问题\n",
      "   3. search_query - 搜索关键词\n",
      "   4. search_results - 搜索结果\n",
      "   5. final_answer - 最终答案\n",
      "   6. step - 当前步骤\n"
     ]
    }
   ],
   "source": [
    "# 定义搜索助手的状态结构\n",
    "class SearchState(TypedDict):\n",
    "    \"\"\"\n",
    "    SearchState 定义了在工作流中流转的所有数据\n",
    "    \n",
    "    - messages: 对话消息列表（用户和 AI 的对话历史）\n",
    "    - user_query: 用户的原始问题\n",
    "    - search_query: 优化后的搜索关键词\n",
    "    - search_results: Tavily 搜索返回的结果\n",
    "    - final_answer: 最终生成的答案\n",
    "    - step: 当前处于哪个步骤（用于调试）\n",
    "    - retry_count: 重试次数（防止无限循环）\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]  # 消息列表，会自动累积\n",
    "    user_query: str        # 用户查询\n",
    "    search_query: str      # 优化后的搜索查询\n",
    "    search_results: str    # Tavily搜索结果\n",
    "    final_answer: str      # 最终答案\n",
    "    step: str             # 当前步骤\n",
    "    retry_count: int      # 重试计数器\n",
    "\n",
    "print(\"✅ 状态结构定义完成！\")\n",
    "print(\"📦 我们的状态包含 6 个字段：\")\n",
    "print(\"   1. messages - 对话历史\")\n",
    "print(\"   2. user_query - 用户问题\")\n",
    "print(\"   3. search_query - 搜索关键词\")\n",
    "print(\"   4. search_results - 搜索结果\")\n",
    "\n",
    "print(\"   5. final_answer - 最终答案\")\n",
    "print(\"   6. step - 当前步骤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037b9d4",
   "metadata": {},
   "source": [
    "### 🤔 什么是 TypedDict？\n",
    "\n",
    "`TypedDict` 是 Python 的一个类型注解工具，它的作用是：\n",
    "- 明确规定字典里有哪些键（key）\n",
    "- 明确每个键对应的值是什么类型\n",
    "- 让编辑器可以提供自动补全和错误检查\n",
    "\n",
    "**简单理解**：就像给字典制定一个\"使用说明书\"。\n",
    "\n",
    "### 🤔 什么是 Annotated？\n",
    "\n",
    "`Annotated[list, add_messages]` 的意思是：\n",
    "- `list` 表示这是一个列表类型\n",
    "- `add_messages` 是额外的元数据，告诉 LangGraph 如何处理这个字段\n",
    "- LangGraph 会自动把新消息添加到列表中，而不是替换整个列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9dbf06",
   "metadata": {},
   "source": [
    "## 第 4 步：初始化 AI 模型和搜索客户端\n",
    "\n",
    "现在我们需要创建两个重要的工具：\n",
    "1. **AI 模型**：用于理解问题和生成答案\n",
    "2. **Tavily 客户端**：用于搜索真实信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27c5958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AI 模型和搜索客户端初始化成功！\n",
      "🤖 使用的模型: gpt-4.1\n",
      "🌡️  温度参数: 1.2 (较高的创造性)\n"
     ]
    }
   ],
   "source": [
    "# 初始化 OpenAI 聊天模型\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL\", \"gpt-4.1\"),  # 模型名称\n",
    "    api_key=os.getenv(\"LLM_API_KEY\"),              # API Key\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\", \"https://api.openai.com/v1\"),  # API 地址\n",
    "    temperature=1.2  # 温度参数：0-2，越高越有创造性，越低越稳定\n",
    ")\n",
    "\n",
    "# 初始化 Tavily 搜索客户端\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "print(\"✅ AI 模型和搜索客户端初始化成功！\")\n",
    "print(f\"🤖 使用的模型: {os.getenv('LLM_MODEL', 'gpt-4.1')}\")\n",
    "print(f\"🌡️  温度参数: 1.2 (较高的创造性)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9e832",
   "metadata": {},
   "source": [
    "### 🌡️ 什么是 temperature（温度参数）？\n",
    "\n",
    "Temperature 控制 AI 生成文本的\"创造性\"：\n",
    "- **0.0 - 0.3**：非常稳定，每次回答几乎一样，适合需要精确答案的场景\n",
    "- **0.4 - 0.7**：适中，既有稳定性又有一定创造性（我们选的这个）\n",
    "- **0.8 - 1.0**：较有创造性，适合创意写作\n",
    "- **1.0 以上**：非常随机，可能产生意想不到的结果\n",
    "\n",
    "对于搜索助手，我们选择 0.7，平衡了准确性和灵活性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a8d1a",
   "metadata": {},
   "source": [
    "## 第 5 步：创建第一个节点 - 理解查询\n",
    "\n",
    "在 LangGraph 中，**节点（Node）** 是处理逻辑的单元。每个节点都是一个函数，接收状态，处理后返回更新的状态。\n",
    "\n",
    "我们的第一个节点的任务是：理解用户问题，并生成最佳搜索关键词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4941e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 节点 1 [理解查询] 创建完成！\n"
     ]
    }
   ],
   "source": [
    "def understand_query_node(state: SearchState) -> SearchState:\n",
    "    \"\"\"\n",
    "    节点 1：理解用户查询并生成搜索关键词\n",
    "    \n",
    "    输入：包含用户消息的状态\n",
    "    输出：更新后的状态（包含理解结果和搜索关键词）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 步骤 1：从消息列表中找到最新的用户消息\n",
    "    user_message = \"\"\n",
    "    for msg in reversed(state[\"messages\"]):  # reversed从后往前遍历\n",
    "        if isinstance(msg, HumanMessage):     # 如果msg是HumanMessage，就提取\n",
    "            user_message = msg.content\n",
    "            break\n",
    "    \n",
    "    # 步骤 2：构造提示词，让 AI 分析用户需求\n",
    "    understand_prompt = f\"\"\"分析用户的查询：\"{user_message}\"\n",
    "\n",
    "请完成两个任务：\n",
    "1. 简洁总结用户想要了解什么\n",
    "2. 生成最适合搜索的关键词（中英文均可，要精准）\n",
    "\n",
    "格式：\n",
    "理解：[用户需求总结]\n",
    "搜索词：[最佳搜索关键词]\"\"\"\n",
    "\n",
    "    # 步骤 3：调用 AI 模型生成理解和搜索词\n",
    "    response = llm.invoke([SystemMessage(content=understand_prompt)])\n",
    "    \n",
    "    # 步骤 4：从 AI 回复中提取搜索关键词\n",
    "    response_text = response.content\n",
    "    search_query = user_message  # 默认使用原始查询\n",
    "    \n",
    "    # 尝试提取\"搜索词：\"后面的内容\n",
    "    if \"搜索词：\" in response_text:\n",
    "        search_query = response_text.split(\"搜索词：\")[1].strip()\n",
    "    elif \"搜索关键词：\" in response_text:\n",
    "        search_query = response_text.split(\"搜索关键词：\")[1].strip()\n",
    "    \n",
    "    # 步骤 5：返回更新后的状态\n",
    "    return {\n",
    "        \"user_query\": response.content,\n",
    "        \"search_query\": search_query,\n",
    "        \"step\": \"understood\",\n",
    "        \"messages\": [AIMessage(content=f\"我理解您的需求：{response.content}\")]\n",
    "    }\n",
    "\n",
    "print(\"✅ 节点 1 [理解查询] 创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37de6dd",
   "metadata": {},
   "source": [
    "### 🔍 代码详解\n",
    "\n",
    "这个节点做了 5 件事：\n",
    "\n",
    "1. **找到用户消息**：从对话历史中找到最新的用户问题\n",
    "2. **构造提示词**：告诉 AI 要做什么（分析需求 + 生成搜索词）\n",
    "3. **调用 AI**：让 AI 处理并返回结果\n",
    "4. **提取关键词**：从 AI 的回复中解析出搜索关键词\n",
    "5. **返回更新**：把新信息加入状态，传给下一个节点\n",
    "\n",
    "**关键概念**：\n",
    "- `state[\"messages\"]`：当前的对话历史\n",
    "- `HumanMessage`：表示用户发的消息\n",
    "- `AIMessage`：表示 AI 发的消息\n",
    "- `SystemMessage`：表示系统指令（不显示给用户）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b080c5",
   "metadata": {},
   "source": [
    "## 第 6 步：创建第二个节点 - 搜索信息\n",
    "\n",
    "第二个节点的任务是：使用 Tavily API 搜索真实信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57b04dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 节点 2 [搜索信息] 创建完成！\n"
     ]
    }
   ],
   "source": [
    "def tavily_search_node(state: SearchState) -> SearchState:\n",
    "    \"\"\"\n",
    "    节点 2：使用 Tavily API 进行真实搜索\n",
    "    \n",
    "    输入：包含搜索关键词的状态\n",
    "    输出：更新后的状态（包含搜索结果）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从状态中获取搜索关键词\n",
    "    search_query = state[\"search_query\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔍 正在搜索: {search_query}\")\n",
    "        \n",
    "        # 调用 Tavily 搜索 API\n",
    "        response = tavily_client.search(\n",
    "            query=search_query,           # 搜索关键词\n",
    "            search_depth=\"basic\",         # 搜索深度（basic 或 advanced）\n",
    "            include_answer=True,          # 是否包含 AI 生成的综合答案\n",
    "            include_raw_content=False,    # 是否包含原始网页内容\n",
    "            max_results=5                 # 最多返回 5 个结果\n",
    "        )\n",
    "        \n",
    "        # 处理搜索结果\n",
    "        search_results = \"\"\n",
    "        \n",
    "        # 优先使用 Tavily 的综合答案\n",
    "        if response.get(\"answer\"):\n",
    "            search_results = f\"综合答案：\\n{response['answer']}\\n\\n\"\n",
    "        \n",
    "        # 添加具体的搜索结果（取前 3 个）\n",
    "        if response.get(\"results\"):\n",
    "            search_results += \"相关信息：\\n\"\n",
    "            for i, result in enumerate(response[\"results\"][:3], 1):\n",
    "                title = result.get(\"title\", \"\")\n",
    "                content = result.get(\"content\", \"\")\n",
    "                url = result.get(\"url\", \"\")\n",
    "                search_results += f\"{i}. {title}\\n{content}\\n来源：{url}\\n\\n\"\n",
    "        \n",
    "        # 如果没有找到任何结果\n",
    "        if not search_results:\n",
    "            search_results = \"抱歉，没有找到相关信息。\"\n",
    "        \n",
    "        # 返回更新后的状态\n",
    "        return {\n",
    "            \"search_results\": search_results,\n",
    "            \"step\": \"searched\",\n",
    "            \"messages\": [AIMessage(content=f\"✅ 搜索完成！找到了相关信息，正在为您整理答案...\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 如果搜索出错，记录错误信息\n",
    "        error_msg = f\"搜索时发生错误: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        \n",
    "        return {\n",
    "            \"search_results\": f\"搜索失败：{error_msg}\",\n",
    "            \"step\": \"search_failed\",\n",
    "            \"messages\": [AIMessage(content=\"❌ 搜索遇到问题，我将基于已有知识为您回答\")]\n",
    "        }\n",
    "\n",
    "print(\"✅ 节点 2 [搜索信息] 创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142544f",
   "metadata": {},
   "source": [
    "### 🔍 Tavily API 参数说明\n",
    "\n",
    "- **query**: 你要搜索的关键词\n",
    "- **search_depth**: \n",
    "  - `\"basic\"` - 快速搜索，返回基本结果\n",
    "  - `\"advanced\"` - 深度搜索，更全面但更慢\n",
    "- **include_answer**: 是否让 Tavily 生成一个综合答案\n",
    "- **include_raw_content**: 是否包含完整的网页内容（通常不需要）\n",
    "- **max_results**: 最多返回多少个搜索结果\n",
    "\n",
    "### 🛡️ 错误处理\n",
    "\n",
    "注意我们用了 `try...except` 来捕获可能的错误：\n",
    "- API 调用失败\n",
    "- 网络问题\n",
    "- API Key 无效\n",
    "\n",
    "这样即使搜索失败，程序也不会崩溃。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a9308",
   "metadata": {},
   "source": [
    "## 第 7 步：创建第三个节点 - 生成答案\n",
    "\n",
    "第三个节点的任务是：基于搜索结果，生成完整、准确的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43117a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 节点 3 [生成答案] 创建完成！\n"
     ]
    }
   ],
   "source": [
    "def generate_answer_node(state: SearchState) -> SearchState:\n",
    "    \"\"\"\n",
    "    节点 3：基于搜索结果生成最终答案\n",
    "    \n",
    "    输入：包含搜索结果的状态\n",
    "    输出：最终的回答\n",
    "    \"\"\"\n",
    "    print(\"🧠 正在生成答案...\")\n",
    "    # 检查搜索是否失败\n",
    "    if state[\"step\"] == \"search_failed\":\n",
    "        # 如果搜索失败，让 AI 基于自己的知识回答\n",
    "        fallback_prompt = f\"\"\"搜索API暂时不可用，请基于您的知识回答用户的问题：\n",
    "\n",
    "用户问题：{state['user_query']}\n",
    "\n",
    "请提供一个有用的回答，并说明这是基于已有知识的回答。\"\"\"\n",
    "        \n",
    "        response = llm.invoke([SystemMessage(content=fallback_prompt)])\n",
    "        \n",
    "        return {\n",
    "            \"final_answer\": response.content,\n",
    "            \"step\": \"completed\",\n",
    "            \"messages\": [AIMessage(content=response.content)]\n",
    "        }\n",
    "    \n",
    "    # 基于搜索结果生成答案\n",
    "    answer_prompt = f\"\"\"基于以下搜索结果为用户提供完整、准确的答案：\n",
    "\n",
    "用户问题：{state['user_query']}\n",
    "\n",
    "搜索结果：\n",
    "{state['search_results']}\n",
    "\n",
    "请要求：\n",
    "1. 综合搜索结果，提供准确、有用的回答\n",
    "2. 如果是技术问题，提供具体的解决方案或代码\n",
    "3. 引用重要信息的来源\n",
    "4. 回答要结构清晰、易于理解\n",
    "5. 如果搜索结果不够完整，请说明并提供补充建议\"\"\"\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=answer_prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": response.content,\n",
    "        \"step\": \"completed\",\n",
    "        \"messages\": [AIMessage(content=response.content)]\n",
    "    }\n",
    "\n",
    "print(\"✅ 节点 3 [生成答案] 创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2ae26",
   "metadata": {},
   "source": [
    "## 第 8 步：创建第四个节点 - 反思答案是否符合用户预期\n",
    "\n",
    "第四个节点的任务是：基于答案和用户的原始问题，评估生成的答案质量，并判断是否需要重新生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb1ce3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 节点 4 [反思评估] 创建完成！\n"
     ]
    }
   ],
   "source": [
    "def reflect_node(state: SearchState) -> SearchState:\n",
    "    \"\"\"反思节点：评估生成的答案质量\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_response = messages[-1].content\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    \n",
    "    print(f\"🔍 正在评估答案质量... (当前重试次数: {retry_count})\")\n",
    "    \n",
    "    # 构建反思提示词\n",
    "    reflection_prompt = f\"\"\"\n",
    "    请作为一名严谨的审阅者，评估以下答案是否准确完整地回答了用户问题。\n",
    "    答案：{last_response}\n",
    "    \n",
    "    如果通过，请回答 \"PASS\"；如果不通过或需要改进，请说明理由并回答 \"FAIL\"。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 调用 LLM 进行评估\n",
    "    result = llm.invoke([SystemMessage(content=reflection_prompt)])\n",
    "    \n",
    "    if \"PASS\" in result.content.upper():\n",
    "        # 获取最终答案，在通过时才展示\n",
    "        final_answer = state.get(\"final_answer\", \"\")\n",
    "        return {\n",
    "            \"step\": \"end\",\n",
    "            \"final_answer\": final_answer,\n",
    "            \"messages\": [\n",
    "                AIMessage(content=f\"\\n💡 最终回答:\\n{final_answer}\"),\n",
    "                AIMessage(content=\"✅ 答案质量评估 PASS，结束对话。\")\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        # 增加重试计数\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"❌ 答案需要改进: {result.content}\")],\n",
    "            \"retry_count\": retry_count + 1\n",
    "        }\n",
    "\n",
    "print(\"✅ 节点 4 [反思评估] 创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f21819",
   "metadata": {},
   "source": [
    "# 创建及reflection节点的出边规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3765a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def should_continue(state: SearchState):\n",
    "    \"\"\"根据反思结果决定路径\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.upper()\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    \n",
    "    # 检查是否通过\n",
    "    if \"PASS\" in last_message:\n",
    "        return \"end\"\n",
    "    \n",
    "\n",
    "    # 检查是否超过最大重试次数（防止无限循环）\n",
    "\n",
    "    MAX_RETRIES = 4   \n",
    "\n",
    "    if retry_count >= MAX_RETRIES:    \n",
    "        print(f\"⚠️ 已达到最大重试次数 ({MAX_RETRIES})，强制结束\")       \n",
    "        return \"end\"\n",
    "    #未通过且未超过重试次数，继续重试\n",
    "    return \"retry\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733a7f2",
   "metadata": {},
   "source": [
    "### 💡 两种情况的处理\n",
    "\n",
    "这个节点处理两种情况：\n",
    "\n",
    "1. **搜索成功**：基于搜索结果生成答案\n",
    "   - 综合多个来源的信息\n",
    "   - 引用来源链接\n",
    "   - 结构化呈现\n",
    "\n",
    "2. **搜索失败**：基于 AI 自身知识回答\n",
    "   - 告知用户这是基于已有知识\n",
    "   - 尽力提供有用信息\n",
    "   - 提示可能不是最新的\n",
    "\n",
    "这种设计叫做\"优雅降级\"（Graceful Degradation），即使某个环节出错，系统仍然能提供服务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad48d6b",
   "metadata": {},
   "source": [
    "## 第 8 步：构建完整的工作流\n",
    "\n",
    "现在我们有了三个节点，接下来要把它们连接起来，形成一个完整的工作流。\n",
    "\n",
    "这就是 LangGraph 的核心功能：**图（Graph）结构**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28421a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 工作流构建完成！\n",
      "📊 工作流结构：\n",
      "   START → 理解查询 → 搜索信息 → 生成答案 → 反思评估 → END 或 重新开始\n"
     ]
    }
   ],
   "source": [
    "def create_search_assistant():\n",
    "    \"\"\"\n",
    "    创建智能搜索助手工作流\n",
    "    \n",
    "    工作流程：\n",
    "    START → 理解查询 → 搜索信息 → 生成答案 → END\n",
    "    \"\"\"\n",
    "    \n",
    "    # 创建状态图（StateGraph）\n",
    "    workflow = StateGraph(SearchState)\n",
    "    \n",
    "    # 添加四个节点\n",
    "    workflow.add_node(\"understand\", understand_query_node)\n",
    "    workflow.add_node(\"search\", tavily_search_node)\n",
    "    workflow.add_node(\"answer\", generate_answer_node)\n",
    "    workflow.add_node(\"reflect\", reflect_node)\n",
    "    \n",
    "    # 设置节点之间的连接（边）\n",
    "    workflow.add_edge(START, \"understand\")      # 开始 → 理解查询\n",
    "    workflow.add_edge(\"understand\", \"search\")   # 理解查询 → 搜索信息\n",
    "    workflow.add_edge(\"search\", \"answer\")       # 搜索信息 → 生成答案\n",
    "    workflow.add_edge(\"answer\", \"reflect\")      # 生成答案 → 反思评估\n",
    "    workflow.add_conditional_edges(\n",
    "        \"reflect\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"end\": END,       # 反思评估 → 结束\n",
    "            \"retry\": \"understand\" # 反思评估 → 重新生成答案\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 创建内存存储器（用于保存对话历史）\n",
    "    memory = InMemorySaver()\n",
    "    \n",
    "    # 编译图（compile），生成可执行的应用\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "print(\"✅ 工作流构建完成！\")\n",
    "print(\"📊 工作流结构：\")\n",
    "print(\"   START → 理解查询 → 搜索信息 → 生成答案 → 反思评估 → END 或 重新开始\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a665a",
   "metadata": {},
   "source": [
    "### 🗺️ 理解工作流图\n",
    "\n",
    "想象一下，我们创建了一条\"流水线\"：\n",
    "\n",
    "```\n",
    "   用户问题\n",
    "      ↓\n",
    "[节点1: 理解查询]  ← 分析问题，生成搜索词\n",
    "      ↓\n",
    "[节点2: 搜索信息]  ← 调用 Tavily API\n",
    "      ↓\n",
    "[节点3: 生成答案]  ← 基于搜索结果回答\n",
    "      ↓\n",
    "   最终答案\n",
    "```\n",
    "\n",
    "**关键概念**：\n",
    "- `StateGraph`：状态图，用于定义工作流\n",
    "- `add_node`：添加一个处理节点\n",
    "- `add_edge`：连接两个节点（定义执行顺序）\n",
    "- `compile`：编译图，生成可运行的应用\n",
    "- `InMemorySaver`：内存存储器，保存对话历史\n",
    "\n",
    "### 🔄 为什么需要 memory？\n",
    "\n",
    "Memory（内存）用于保存对话历史，这样：\n",
    "- 你可以问连续的问题\n",
    "- AI 能记住之前讨论的内容\n",
    "- 支持多轮对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb5703",
   "metadata": {},
   "source": [
    "## 第 9 步：编写主函数 - 运行助手\n",
    "\n",
    "最后，我们需要一个主函数来运行这个智能助手，并与用户交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9720d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 主函数创建完成！\n",
      "💡 使用 asyncio.run(main()) 来运行助手\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    主函数：运行智能搜索助手\n",
    "    \n",
    "    功能：\n",
    "    1. 检查 API Key 是否配置\n",
    "    2. 创建搜索助手应用\n",
    "    3. 循环接收用户输入\n",
    "    4. 执行工作流并显示结果\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查 Tavily API Key 是否配置\n",
    "    if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "        print(\"❌ 错误：请在 .env 文件中配置 TAVILY_API_KEY\")\n",
    "        return\n",
    "    \n",
    "    # 创建搜索助手应用\n",
    "    app = create_search_assistant()\n",
    "    \n",
    "    # 欢迎信息\n",
    "    print(\"🔍 智能搜索助手启动！\")\n",
    "    print(\"我会使用 Tavily API 为您搜索最新、最准确的信息\")\n",
    "    print(\"支持各种问题：新闻、技术、知识问答等\")\n",
    "    print(\"(输入 'quit' 退出)\\n\")\n",
    "    \n",
    "    session_count = 0  # 会话计数器\n",
    "    \n",
    "    # 主循环：不断接收用户输入\n",
    "    while True:\n",
    "        user_input = input(\"🤔 您想了解什么: \").strip()\n",
    "        \n",
    "        # 检查是否退出\n",
    "        if user_input.lower() in ['quit', 'q', '退出', 'exit']:\n",
    "            print(\"感谢使用！再见！👋\")\n",
    "            break\n",
    "        \n",
    "        # 跳过空输入\n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # 为每次对话创建唯一的会话 ID，以便区分不同的对话历史\n",
    "        # 如果不设置config，每次调用都会作为新对话，无法记住上一轮的历史\n",
    "        session_count += 1\n",
    "        config = {\"configurable\": {\"thread_id\": f\"search-session-{session_count}\"}}\n",
    "        \n",
    "        # 构造初始状态\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=user_input)],\n",
    "            \"user_query\": \"\",\n",
    "            \"search_query\": \"\",\n",
    "            \"search_results\": \"\",\n",
    "            \"final_answer\": \"\",\n",
    "            \"step\": \"start\",\n",
    "            \"retry_count\": 0  # 初始化重试计数器\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            \n",
    "            # 执行工作流（异步流式输出）\n",
    "            async for output in app.astream(initial_state, config=config):\n",
    "                # 遍历每个节点的输出\n",
    "                for node_name, node_output in output.items():\n",
    "                    if \"messages\" in node_output and node_output[\"messages\"]:\n",
    "                        # 根据节点名称显示不同的提示\n",
    "                        if node_name == \"understand\":\n",
    "                            latest_message = node_output[\"messages\"][-1]\n",
    "                            if isinstance(latest_message, AIMessage):\n",
    "                                print(f\"🧠 理解阶段: {latest_message.content}\")\n",
    "                        elif node_name == \"search\":\n",
    "                            latest_message = node_output[\"messages\"][-1]\n",
    "                            if isinstance(latest_message, AIMessage):\n",
    "                                print(f\"🔍 搜索阶段: {latest_message.content}\")\n",
    "                        elif node_name == \"answer\":\n",
    "                            print(f\"🧠 正在生成答案...\")\n",
    "                        elif node_name == \"reflect\":\n",
    "                            # reflect 节点可能返回多条消息（答案 + PASS确认），需要全部打印\n",
    "                            for msg in node_output[\"messages\"]:\n",
    "                                if isinstance(msg, AIMessage):\n",
    "                                    print(f\"{msg.content}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 发生错误: {e}\")\n",
    "            print(\"请重新输入您的问题。\\n\")\n",
    "\n",
    "print(\"✅ 主函数创建完成！\")\n",
    "print(\"💡 使用 asyncio.run(main()) 来运行助手\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9faac0",
   "metadata": {},
   "source": [
    "### 🔄 异步编程（async/await）简介\n",
    "\n",
    "你可能注意到函数前面有 `async`，调用时用 `await`：\n",
    "\n",
    "```python\n",
    "async def main():  # async 定义异步函数\n",
    "    async for output in app.astream(...):  # async for 异步遍历\n",
    "        ...\n",
    "```\n",
    "\n",
    "**为什么要用异步？**\n",
    "- AI 调用和 API 请求需要等待（几秒钟）\n",
    "- 异步让程序在等待时可以做其他事情\n",
    "- 提高效率，避免\"卡住\"\n",
    "\n",
    "**简单理解**：\n",
    "- 同步 = 排队办事（一个一个来）\n",
    "- 异步 = 取号办事（等待时可以做其他事）\n",
    "\n",
    "### 🆔 什么是 thread_id？\n",
    "\n",
    "`thread_id` 是会话 ID，用于区分不同的对话：\n",
    "- 每次新对话有一个新的 ID\n",
    "- LangGraph 用它来管理对话历史\n",
    "- 相同 ID 的对话会共享历史记录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470e0d1",
   "metadata": {},
   "source": [
    "## 第 10 步：运行智能搜索助手！\n",
    "\n",
    "现在一切准备就绪，让我们运行助手试试看！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef752e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 智能搜索助手启动！\n",
      "我会使用 Tavily API 为您搜索最新、最准确的信息\n",
      "支持各种问题：新闻、技术、知识问答等\n",
      "(输入 'quit' 退出)\n",
      "\n",
      "\n",
      "============================================================\n",
      "🧠 理解阶段: 我理解您的需求：理解：用户希望用特别简单、易懂、适合老年人（如奶奶）理解的方式介绍transformer（人工智能中的一种技术或模型）。\n",
      "\n",
      "搜索词：transformer简单解释，通俗介绍transformer，老人也能听懂的transformer，Transformer plain explanation, transformer for beginners, AI transformer for seniors\n",
      "🔍 正在搜索: transformer简单解释，通俗介绍transformer，老人也能听懂的transformer，Transformer plain explanation, transformer for beginners, AI transformer for seniors\n",
      "🔍 搜索阶段: ✅ 搜索完成！找到了相关信息，正在为您整理答案...\n",
      "🧠 正在生成答案...\n",
      "🧠 正在生成答案...\n",
      "🔍 正在评估答案质量... (当前重试次数: 0)\n",
      "\n",
      "💡 最终回答:\n",
      "好的，下面用特别简单、适合老人（如奶奶）理解的方式介绍人工智能中的 “Transformer” 技术。\n",
      "\n",
      "---\n",
      "\n",
      "### 什么是“Transformer”（变压器）？\n",
      "\n",
      "**Transformer** 是一种让人工智能变得非常聪明的工具，就像大脑一样，能处理大量的信息。主要用于翻译语言、自动写文章等任务。\n",
      "\n",
      "---\n",
      "\n",
      "#### 简单解释（老人能懂的版本）\n",
      "\n",
      "假如奶奶在看一本书，不是每一页、每一个词都仔细看，而是会关注那些有用、有意思的段落。Transformer 的工作方式就像奶奶读书的习惯——它会快速“阅读”，抓住重点信息。\n",
      "\n",
      "##### 如何理解 Transformer 工作方式？\n",
      "\n",
      "- **并不是一步步处理，而是一次处理所有信息。**\n",
      "- 它会把一大堆句子、文字“分块”，然后每个块都能被重点关注。\n",
      "- Transformer 用一种叫“注意力”的方法，突出每块特别重要的信息（比如句子的主旨）。\n",
      "\n",
      "##### 有什么好处？\n",
      "\n",
      "比如外国文字翻译成中文：\n",
      "- Transformer 能忙里偷闲，只关注要翻译的重点。\n",
      "- 翻译速度快，效果好。\n",
      "\n",
      "---\n",
      "\n",
      "### 比如，奶奶想翻译一句英文\n",
      "\n",
      "以前的人工智能要一步步翻译，现在的 Transformer 可以快捷地把整句话理解后，快快翻译成中文，还能判断句子里最重要的词。\n",
      "\n",
      "---\n",
      "\n",
      "### 总结一句话\n",
      "\n",
      "> Transformer 就像一个聪明的助手，能帮人抓住重点，快速且准确地完成任务，比如翻译、写文章、答问题。\n",
      "\n",
      "---\n",
      "\n",
      "#### 来源参考\n",
      "- Transformers in AI, explained for初学者：[YouTube 介绍视频](https://www.youtube.com/watch?v=4Vy0wKtuUtY)\n",
      "- 更详细介绍：[YouTube高级讲解](https://www.youtube.com/watch?v=svgBWTZUsdQ)\n",
      "\n",
      "---\n",
      "\n",
      "### 如果还不明白，建议看Youtube里用动画和简单语言解释的视频，帮助进一步理解。\n",
      "\n",
      "---\n",
      "\n",
      "#### 结构总结\n",
      "1. 简单介绍 Transformer\n",
      "2. 用生活化例子类比\n",
      "3. 回答为什么有用\n",
      "4. 提供进一步学习参考\n",
      "5. 推荐视频帮助辅助理解\n",
      "\n",
      "---\n",
      "\n",
      "如果还有疑惑，欢迎继续提问。\n",
      "✅ 答案质量评估 PASS，结束对话。\n",
      "\n",
      "============================================================\n",
      "\n",
      "感谢使用！再见！👋\n"
     ]
    }
   ],
   "source": [
    "# 运行智能搜索助手\n",
    "# 注意：在 Jupyter 中使用 await，在普通 Python 脚本中使用 asyncio.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 在 Jupyter 中可以直接 await\n",
    "    await main()\n",
    "    \n",
    "    # 在普通 Python 脚本（.py 文件）中应该用：\n",
    "    # asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fbef2",
   "metadata": {},
   "source": [
    "## 🎉 恭喜你完成了教程！\n",
    "\n",
    "### 📚 你学到了什么\n",
    "\n",
    "1. ✅ **LangGraph 基础**\n",
    "   - 什么是状态（State）\n",
    "   - 什么是节点（Node）\n",
    "   - 如何构建工作流图（Graph）\n",
    "\n",
    "2. ✅ **实践技能**\n",
    "   - 定义 TypedDict 状态结构\n",
    "   - 创建处理节点函数\n",
    "   - 连接节点形成工作流\n",
    "   - 集成外部 API（Tavily）\n",
    "   - 异步编程基础\n",
    "\n",
    "3. ✅ **工程实践**\n",
    "   - 环境变量管理\n",
    "   - 错误处理\n",
    "   - 代码结构组织\n",
    "\n",
    "### 🚀 下一步可以做什么\n",
    "\n",
    "1. **扩展节点**：添加更多处理步骤\n",
    "   - 结果过滤节点\n",
    "   - 内容摘要节点\n",
    "   - 多语言翻译节点\n",
    "\n",
    "2. **改进搜索**：使用更高级的搜索策略\n",
    "   - 多关键词搜索\n",
    "   - 搜索结果排序\n",
    "   - 自动重试机制\n",
    "\n",
    "3. **添加条件分支**：根据不同情况走不同路径\n",
    "   - 如果是编程问题 → 搜索代码示例\n",
    "   - 如果是新闻问题 → 搜索最新资讯\n",
    "   - 使用 `add_conditional_edges` 实现\n",
    "\n",
    "4. **持久化存储**：将对话保存到数据库\n",
    "   - 使用 SQLite、Redis 等\n",
    "   - 跨会话对话历史\n",
    "\n",
    "### 📖 推荐资源\n",
    "\n",
    "- [LangGraph 官方文档](https://python.langchain.com/docs/langgraph)\n",
    "- [Tavily API 文档](https://docs.tavily.com/)\n",
    "- [LangChain 教程](https://python.langchain.com/docs/get_started/introduction)\n",
    "\n",
    "### 💬 遇到问题？\n",
    "\n",
    "常见问题：\n",
    "1. **API Key 错误**：检查 .env 文件配置\n",
    "2. **依赖冲突**：使用虚拟环境隔离项目\n",
    "3. **网络问题**：确保能访问 OpenAI 和 Tavily API\n",
    "\n",
    "祝你学习愉快！🎓✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
